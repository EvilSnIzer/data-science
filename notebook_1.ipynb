{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Trader Behavior vs Market Sentiment \u2014 Full Notebook\n", "\n", "This Colab notebook reproduces the full analysis:\n", "1. Load historical trades & Fear & Greed Index data.\n", "2. Clean & preprocess.\n", "3. Merge by date and compute metrics.\n", "4. Generate visualizations.\n", "5. Summarize insights.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Install libraries if missing (Colab)\n", "!pip install pandas matplotlib\n", "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Load datasets\n", "# Replace with your file paths in Colab (after uploading or mounting Drive)\n", "historical = pd.read_csv('historical_data.csv')\n", "fg = pd.read_csv('fear_greed_index.csv')\n", "print('Historical shape:', historical.shape)\n", "print('Fear & Greed shape:', fg.shape)\n", "historical.head(), fg.head()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Normalize columns\n", "def normalize_cols(df):\n", "    df = df.copy()\n", "    df.columns = (\n", "        df.columns.str.strip().str.lower().str.replace('[^0-9a-zA-Z]+','_',regex=True).str.strip('_')\n", "    )\n", "    return df\n", "\n", "hist = normalize_cols(historical)\n", "fg2 = normalize_cols(fg)\n", "hist.head()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Parse timestamps\n", "import numpy as np\n", "if 'timestamp' in hist.columns:\n", "    v = pd.to_numeric(hist['timestamp'], errors='coerce')\n", "    unit = 'ms' if v.dropna().median() > 1e12 else 's'\n", "    hist['dt'] = pd.to_datetime(v, unit=unit, utc=True)\n", "elif 'timestamp_ist' in hist.columns:\n", "    hist['dt'] = pd.to_datetime(hist['timestamp_ist'], errors='coerce')\n", "else:\n", "    hist['dt'] = pd.NaT\n", "\n", "hist['date'] = hist['dt'].dt.date\n", "hist.head()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Compute notional\n", "if 'size_usd' in hist.columns:\n", "    hist['notional'] = hist['size_usd'].abs()\n", "elif 'execution_price' in hist.columns and 'size_tokens' in hist.columns:\n", "    hist['notional'] = (hist['execution_price'].abs() * hist['size_tokens'].abs())\n", "else:\n", "    hist['notional'] = np.nan\n", "\n", "# Parse FGI\n", "fg2['date'] = pd.to_datetime(fg2['date'], errors='coerce').dt.date\n", "fg_clean = fg2[['date','classification','value']].dropna(subset=['date']).drop_duplicates()\n", "\n", "# Merge\n", "merged = pd.merge(hist, fg_clean, on='date', how='left')\n", "merged['win'] = (merged['closed_pnl'] > 0).astype(int)\n", "merged.head()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Aggregate by sentiment\n", "by_sent = merged.groupby('classification').agg({\n", "    'closed_pnl': ['sum','mean','median','std','count'],\n", "    'notional': ['sum','mean','median','std'],\n", "    'win': ['mean']\n", "})\n", "by_sent"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Daily metrics\n", "daily = merged.groupby(['date','classification']).agg({\n", "    'closed_pnl': ['sum','mean'],\n", "    'notional': ['sum'],\n", "    'win': ['mean']\n", "}).reset_index()\n", "daily.head()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {}, "source": ["# Charts\n", "pivot_pnl = daily.pivot(index='date', columns='classification', values=('closed_pnl','sum'))\n", "pivot_pnl.plot(figsize=(10,4))\n", "plt.title('Daily Realized PnL by Sentiment')\n", "plt.show()\n", "\n", "pivot_notional = daily.pivot(index='date', columns='classification', values=('notional','sum'))\n", "pivot_notional.plot(figsize=(10,4))\n", "plt.title('Daily Notional Volume by Sentiment')\n", "plt.show()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Next Steps\n", "- You can extend with statistical tests (t-test between Greed vs Fear).\n", "- Add regression models for predictive analysis.\n", "- Save CSV outputs and charts for reporting.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}